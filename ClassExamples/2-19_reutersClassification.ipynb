{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DvRNgHS3feO",
        "outputId": "0ddfd4da-13f2-4e97-9160-29f8733bfbff"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import reuters\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, SimpleRNN\n",
        "import numpy as np\n",
        "from keras.layers import Dropout\n",
        "\n",
        "\n",
        "max_words = 10000\n",
        "\n",
        "# Load the Reuters dataset\n",
        "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_words, test_split=0.2)\n",
        "\n",
        "# Get the class names\n",
        "class_names = [\"cocoa\",\"grain\",\"veg-oil\",\"earn\",\"acq\",\"wheat\",\"copper\",\"housing\",\"money-supply\",\n",
        "               \"coffee\",\"sugar\",\"trade\",\"reserves\",\"ship\",\"cotton\",\"carcass\",\"crude\",\"nat-gas\",\n",
        "               \"cpi\",\"money-fx\",\"interest\",\"gnp\",\"meal-feed\",\"alum\",\"oilseed\",\"gold\",\"tin\",\n",
        "               \"strategic-metal\",\"livestock\",\"retail\",\"ipi\",\"iron-steel\",\"rubber\",\"heat\",\"jobs\",\n",
        "               \"lei\",\"bop\",\"zinc\",\"orange\",\"pet-chem\",\"dlr\",\"gas\",\"silver\",\"wpi\",\"hog\",\"lead\"]\n",
        "\n",
        "# One of the simplest ways to represent text \n",
        "# word_index[word] = index\n",
        "# Define the word index \n",
        "word_index = reuters.get_word_index() \n",
        "word_index = {k: (v+3) for k, v in word_index.items()}\n",
        "word_index['<PAD>'] = 0\n",
        "word_index['<START>'] = 1\n",
        "word_index['<UNK>'] = 2\n",
        "word_index['<UNUSED>'] = 3\n",
        "\n",
        "# Reverse word index\n",
        "# reverse_word_index[index] = word\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "# Set the maximum sequence length\n",
        "maxlen = 100\n",
        "\n",
        "# Pad the sequences\n",
        "# All words need to have the same size\n",
        "# Padding at the end (can also pad at the beginning)\n",
        "x_train = pad_sequences(x_train, padding='post', maxlen=maxlen)  \n",
        "x_test = pad_sequences(x_test, padding='post', maxlen=maxlen) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LF0p1Tbm9T8j"
      },
      "outputs": [],
      "source": [
        "# One-hot encode the labels\n",
        "# Converts class number to bit (to prevent model from liking high numbers)\n",
        "num_classes = len(class_names)\n",
        "y_train_one_hot = to_categorical(y_train, num_classes)\n",
        "y_test_one_hot = to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfRjhoQ-8uih",
        "outputId": "bfc55688-ee7c-49b5-c8f4-2e334eccbcb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "64/64 [==============================] - 27s 359ms/step - loss: 2.8849 - accuracy: 0.2784 - val_loss: 2.6895 - val_accuracy: 0.3315\n",
            "Epoch 2/10\n",
            "64/64 [==============================] - 23s 367ms/step - loss: 2.6931 - accuracy: 0.3055 - val_loss: 2.6094 - val_accuracy: 0.3315\n",
            "Epoch 3/10\n",
            "64/64 [==============================] - 20s 320ms/step - loss: 2.6100 - accuracy: 0.3141 - val_loss: 2.5523 - val_accuracy: 0.3315\n",
            "Epoch 4/10\n",
            "64/64 [==============================] - 22s 350ms/step - loss: 2.7314 - accuracy: 0.2998 - val_loss: 2.6602 - val_accuracy: 0.3315\n",
            "Epoch 5/10\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;66;03m# Adapts learning rate  \u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_one_hot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
            "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
            "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
            "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
            "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Define and train the RNN model\n",
        "from keras.layers import Dense, Dropout, Embedding, SimpleRNN\n",
        "from keras.models import Sequential\n",
        "\n",
        "# Define the SimpleRNN model\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, 256))\n",
        "model.add(SimpleRNN(256, activation='tanh', return_sequences=True))\n",
        "model.add(Dropout(0.5)) # Avoid overfitting\n",
        "model.add(SimpleRNN(256, activation='tanh')) # Allows positive and negative\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))  # Can't use sigmoid bc there are multiple classes\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) # Adapts learning rate  \n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train_one_hot, epochs=10, batch_size=128, validation_split=0.1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isnvLD5q-kbW",
        "outputId": "d76f78c4-727c-45ed-f31a-a7983851e396"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 387ms/step\n",
            "Test sample 1: of <UNK> in august 1986 and <UNK> in december helped us achieve better than expected results in the fourth quarter ended february 28 its net income from continuing operations jumped 52 6 pct to 20 7 mln dlrs or 55 cts a share in the latest quarter as sales increased 48 3 pct to 1 58 billion dlrs a and p gave no details on the expanded capital program but it did say it completed the first year of the program during 1986 a and p is 52 4 pct owned by lt <UNK> <UNK> of west germany reuter 3\n",
            "True label: earn, Predicted label: earn (3)\n",
            "\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "Test sample 2: without any justification manila was <UNK> watching washington's moves to cut domestic support prices to 12 cents a pound from 18 cents the u s agriculture department last december slashed its 12 month 1987 sugar import quota from the philippines to 143 780 short tons from 231 660 short tons in 1986 yulo said despite next year's increased production target some philippine mills were expected to shut down at least four of the 41 mills were not working during the 1986 87 season he said we expect two or three more to follow suit during the next season reuter 3\n",
            "True label: sugar, Predicted label: earn (3)\n",
            "\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Test sample 3: for a month and we don't think it's going to get back in line in any nearby time <UNK> said <UNK> said usda will probably narrow back the gulf differentials when and if gulf prices <UNK> if we're off the mark now because we're too high wouldn't we be as much off the mark if we're too low he said while forecasting more adjustments if gulf prices fall <UNK> said no other changes in usda's price system are being planned right now we don't tinker we don't make changes <UNK> and we don't make changes often he said reuter 3\n",
            "True label: grain, Predicted label: earn (3)\n",
            "\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Test sample 4: its senior secured notes semi annual principal payments on the remaining 40 mln dlrs of notes have been satisfied until december 1988 as a result it said the company said the note agreements were amended to reflect an easing of some financial covenants and an increase of interest to 13 5 pct from 13 0 pct until december 1990 it said the <UNK> exercise price for 1 125 000 warrants was also reduced to 50 cts from 1 50 dlrs the company said energy assets agreed to share the costs of increasing production at the oak hill field reuter 3\n",
            "True label: acq, Predicted label: earn (3)\n",
            "\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "Test sample 5: of <UNK> and <UNK> had eased they said weather officials in neighbouring sweden said the icy conditions in the baltic were the worst for 30 years with ships fighting a losing battle to keep moving in the coastal stretches of the gulf of <UNK> which <UNK> finland and sweden the ice is up to one <UNK> thick with <UNK> and <UNK> packing it into almost <UNK> walls three metres high swedish <UNK> officials said weather forecasts say winds may ease during the weekend but a further drop in temperature could bring shipping to a standstill the officials said reuter 3\n",
            "True label: acq, Predicted label: earn (3)\n",
            "\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Test sample 6: <START> shr 12 cts vs 15 cts net 282 000 vs 360 000 revs 5 261 000 vs 5 348 000 avg shrs 2 336 000 vs 2 335 000 year shr 91 cts vs 1 04 dlrs net 2 149 000 vs 2 075 000 revs 28 2 mln vs 28 3 mln avg shrs 2 356 000 vs 2 001 000 note 1986 quarter net includes 72 000 dlr charge from <UNK> of investment tax credit reuter 3 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "True label: earn, Predicted label: earn (3)\n",
            "\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Test sample 7: expects further restructuring of core businesses particularly <UNK> <UNK> this year through staff reductions <UNK> and the consolidation of facilities combustion said the restructuring at <UNK> <UNK> is expected to substantially reduce but not eliminate this year losses in the engineering and construction segment but it said improvement at <UNK> <UNK> is expected to be approximately offset by a number of factors including a somewhat lower level of earnings in the power generation segment than in 1986 financing costs of the <UNK> acquisition costs associated with <UNK> <UNK> technology and operations and delays in waste to energy projects reuter 3\n",
            "True label: earn, Predicted label: earn (3)\n",
            "\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Test sample 8: vs 278 9 mln avg shrs 39 4 mln vs 34 mln year shr 1 91 dlrs vs 1 62 dlrs net 70 5 mln vs 50 5 mln revs 1 3 billion vs 990 5 mln avg shrs 37 mln vs 31 3 mln note on dec one 1986 company acquired holt <UNK> and <UNK> and w b saunders and the <UNK> press and their foreign subsidiaries by including these companies for the single month of december 1986 4th qtr earnings were raised by seven cts per shr and for the year by eight cts per shr reuter 3\n",
            "True label: earn, Predicted label: earn (3)\n",
            "\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Test sample 9: 4 mln vs 4 311 000 year oper shr profit 1 36 dlrs vs loss 43 cts oper net profit 9 817 000 vs loss 2 433 000 revs 35 0 mln vs 13 8 mln avg shrs 7 224 000 vs 6 731 000 note 1985 net includes tax credits of 492 000 dlrs in quarter and 2 433 000 dlrs in year 1985 net both periods excludes 168 000 dlr loss from discontinued operations 1986 net both periods includes pretax gain 21 8 mln dlrs from sale of remaining interest in <UNK> hills n m development reuter 3\n",
            "True label: earn, Predicted label: earn (3)\n",
            "\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Test sample 10: in the second quarter of 1987 assuming no cash payments at current interest rates are received for the rest of 1987 bankers trust estimated that full year net income would be reduced by about 30 mln dlrs bankers trust said it assumes that debt negotiations between brazil and its commercial bank lenders will lead to the resumption of interest payments the negotiations resume in new york on friday when central bank governor francisco gros is expected to ask banks for a 90 day <UNK> of some 9 5 billion dlrs of term debt that <UNK> on april 15 reuter 3\n",
            "True label: earn, Predicted label: earn (3)\n",
            "\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Test sample 11: <START> grain traders said they were still awaiting results of yesterday's u k intervention feed wheat tender for the home market the market sought to buy 340 000 tonnes more than double the remaining 150 000 tonnes available under the current tender however some of the tonnage included <UNK> bids for supplies in the same stores since the tenders started last july <UNK> 000 tonnes of british feed wheat have been sold back to the home market reuter 3 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "True label: wheat, Predicted label: earn (3)\n",
            "\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Test sample 12: <START> <UNK> inc said it sold the plant inventory and certain other assets of some of its industrial chemical operations to plastic <UNK> and technologies inc a privately held company headquartered in <UNK> new jersey terms were not disclosed <UNK> industrial chemical operations are based in fort worth texas and has annual sales of about 17 mln dlrs reuter 3 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "True label: acq, Predicted label: earn (3)\n",
            "\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Test sample 13: the planted area the total planted area was estimated down 290 000 hectares due to the dry fall it said the report said to compensate for the below normal precipitation irrigation has increased as has the use of fertilizer while there are <UNK> where irrigation is not possible most of the wheat crop has access to some water and therefore has emerged from dormancy and is doing well the report said it said scattered rain in many parts of china in the past 10 days has improved the situation but information on <UNK> damage in anhui is <UNK> reuter 3\n",
            "True label: grain, Predicted label: earn (3)\n",
            "\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Test sample 14: <START> period ended january 31 shr 22 cts vs 16 cts net 518 564 vs 374 198 revs 2 090 724 vs 1 614 079 reuter 3 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "True label: earn, Predicted label: earn (3)\n",
            "\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Test sample 15: monopoly over grain shipments was one notable <UNK> it said the awb said the current approach of state based bulk handling authorities is not essential although it said it favoured the authorities maintaining at least their current level of control of storage and transport as long as quality was maintained an <UNK> on port loading costs showed it cost between 26 500 and 34 700 u s dlrs to load a 50 000 tonne vessel at various australian ports compared with 21 200 dlrs at houston and 16 300 at port <UNK> quebec for a 60 000 tonner reuter 3\n",
            "True label: grain, Predicted label: earn (3)\n",
            "\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Test sample 16: 6 mln chips compared to the first quarter plans call for increased imports but an official said boosting imports will be difficult as it depends on sales demand fujitsu ltd itsu t will cut production in accord with miti guidelines and boost imports from currently low levels <UNK> electric industry co ltd <UNK> t will reduce april production by 10 pct from <UNK> 3 2 mln <UNK> is studying ways to increase imports by 10 pct in the fiscal year beginning april 1 from the previous year's total of more than five billion yen a company official said reuter 3\n",
            "True label: trade, Predicted label: earn (3)\n",
            "\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "Test sample 17: <START> <UNK> ltd said it has closed on a 500 000 dlr long term mortgage loan in connection with its previous purchase of a <UNK> fla plant replacing a short term borrowing the company said full production at the plant will start immediately reuter 3 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "True label: alum, Predicted label: earn (3)\n",
            "\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Test sample 18: <START> <UNK> financial corp said its board declared an initial dividend of five cts per share payable april 21 to holders of record march 31 reuter 3 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "True label: earn, Predicted label: earn (3)\n",
            "\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "Test sample 19: <START> the bank of england said it did not operate in the money market during the morning initially the bank forecast a <UNK> shortage of some 300 mln stg for the market today overnight interbank sterling traded at the 11 1 4 1 8 pct level for most of the morning while period rates have eased on the strength of sterling dealers said at 1200 gmt sterling's trade weighted index was up 0 6 at 72 7 reuter 3 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "True label: money-fx, Predicted label: earn (3)\n",
            "\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "Test sample 20: <START> shr 54 cts vs 40 cts net 11 105 000 vs 8 310 000 sales 282 7 mln vs 290 3 mln avg shrs 20 599 000 vs 20 760 000 note per share results restated for may 1986 three for two stock split reuter 3 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "True label: earn, Predicted label: earn (3)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print some samples from the test set along with the predicted label\n",
        "for i in range(20):\n",
        "    x_sample = x_test[i]\n",
        "    y_true = np.argmax(y_test_one_hot[i])\n",
        "    y_pred = np.argmax(model.predict(x_sample.reshape(1, maxlen))[0])\n",
        "    sample_text = ' '.join([reverse_word_index.get(idx, '') for idx in x_sample])\n",
        "    print(f'Test sample {i+1}: {sample_text}')\n",
        "    print(f'True label: {class_names[y_true]}, Predicted label: {class_names[y_pred]} ({y_pred})\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ei5UXSDp-nlc",
        "outputId": "b936a5e4-0614-4124-cdea-8c0cf9ee82b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "71/71 [==============================] - 3s 41ms/step\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "          cocoa       0.00      0.00      0.00        12\n",
            "          grain       0.00      0.00      0.00       105\n",
            "        veg-oil       0.00      0.00      0.00        20\n",
            "           earn       0.38      1.00      0.55       813\n",
            "            acq       0.11      0.02      0.04       474\n",
            "          wheat       0.00      0.00      0.00         5\n",
            "         copper       0.00      0.00      0.00        14\n",
            "        housing       0.00      0.00      0.00         3\n",
            "   money-supply       0.00      0.00      0.00        38\n",
            "         coffee       0.00      0.00      0.00        25\n",
            "          sugar       0.00      0.00      0.00        30\n",
            "          trade       0.00      0.00      0.00        83\n",
            "       reserves       0.00      0.00      0.00        13\n",
            "           ship       0.00      0.00      0.00        37\n",
            "         cotton       0.00      0.00      0.00         2\n",
            "        carcass       0.00      0.00      0.00         9\n",
            "          crude       0.00      0.00      0.00        99\n",
            "        nat-gas       0.00      0.00      0.00        12\n",
            "            cpi       0.00      0.00      0.00        20\n",
            "       money-fx       0.00      0.00      0.00       133\n",
            "       interest       0.00      0.00      0.00        70\n",
            "            gnp       0.00      0.00      0.00        27\n",
            "      meal-feed       0.00      0.00      0.00         7\n",
            "           alum       0.00      0.00      0.00        12\n",
            "        oilseed       0.00      0.00      0.00        19\n",
            "           gold       0.00      0.00      0.00        31\n",
            "            tin       0.00      0.00      0.00         8\n",
            "strategic-metal       0.00      0.00      0.00         4\n",
            "      livestock       0.00      0.00      0.00        10\n",
            "         retail       0.00      0.00      0.00         4\n",
            "            ipi       0.00      0.00      0.00        12\n",
            "     iron-steel       0.00      0.00      0.00        13\n",
            "         rubber       0.00      0.00      0.00        10\n",
            "           heat       0.00      0.00      0.00         5\n",
            "           jobs       0.00      0.00      0.00         7\n",
            "            lei       0.00      0.00      0.00         6\n",
            "            bop       0.00      0.00      0.00        11\n",
            "           zinc       0.00      0.00      0.00         2\n",
            "         orange       0.00      0.00      0.00         3\n",
            "       pet-chem       0.00      0.00      0.00         5\n",
            "            dlr       0.00      0.00      0.00        10\n",
            "            gas       0.00      0.00      0.00         8\n",
            "         silver       0.00      0.00      0.00         3\n",
            "            wpi       0.00      0.00      0.00         6\n",
            "            hog       0.00      0.00      0.00         5\n",
            "           lead       0.00      0.00      0.00         1\n",
            "\n",
            "       accuracy                           0.37      2246\n",
            "      macro avg       0.01      0.02      0.01      2246\n",
            "   weighted avg       0.16      0.37      0.21      2246\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/wwami/.pyenv/versions/3.11.2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/wwami/.pyenv/versions/3.11.2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/wwami/.pyenv/versions/3.11.2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Get the predicted labels\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# Convert the predicted probabilities to labels\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Print the classification report\n",
        "print(classification_report(y_test, y_pred, target_names=class_names))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "JvwGKlkpKmck",
        "outputId": "e61218c0-31f3-400e-e619-34154d09f8f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "64/64 [==============================] - 39s 510ms/step - loss: 2.5093 - accuracy: 0.3421 - val_loss: 2.1964 - val_accuracy: 0.3571\n",
            "Epoch 2/10\n",
            "64/64 [==============================] - 32s 497ms/step - loss: 1.9611 - accuracy: 0.4444 - val_loss: 2.1142 - val_accuracy: 0.4349\n",
            "Epoch 3/10\n",
            "64/64 [==============================] - 32s 496ms/step - loss: 1.7087 - accuracy: 0.5298 - val_loss: 1.7735 - val_accuracy: 0.5439\n",
            "Epoch 4/10\n",
            "64/64 [==============================] - 32s 495ms/step - loss: 1.6192 - accuracy: 0.5638 - val_loss: 1.7557 - val_accuracy: 0.5551\n",
            "Epoch 5/10\n",
            "64/64 [==============================] - 32s 495ms/step - loss: 1.4988 - accuracy: 0.5896 - val_loss: 1.6520 - val_accuracy: 0.5673\n",
            "Epoch 6/10\n",
            "64/64 [==============================] - 32s 498ms/step - loss: 1.4129 - accuracy: 0.6093 - val_loss: 1.6378 - val_accuracy: 0.5951\n",
            "Epoch 7/10\n",
            "64/64 [==============================] - 32s 496ms/step - loss: 1.3376 - accuracy: 0.6354 - val_loss: 1.6015 - val_accuracy: 0.5907\n",
            "Epoch 8/10\n",
            "64/64 [==============================] - 32s 494ms/step - loss: 1.2648 - accuracy: 0.6556 - val_loss: 1.6255 - val_accuracy: 0.5895\n",
            "Epoch 9/10\n",
            "64/64 [==============================] - 32s 496ms/step - loss: 1.2242 - accuracy: 0.6697 - val_loss: 1.6141 - val_accuracy: 0.6051\n",
            "Epoch 10/10\n",
            "64/64 [==============================] - 32s 495ms/step - loss: 1.1030 - accuracy: 0.7091 - val_loss: 1.6288 - val_accuracy: 0.6174\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x1663e5310>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from keras.layers import LSTM\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, 256))\n",
        "model.add(LSTM(128, activation='tanh', return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128, activation='tanh'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train_one_hot, epochs=10, batch_size=128, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZydPJK-qK0zT",
        "outputId": "ce6c2041-d5ca-4ea5-9fdc-8ef53810df65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "71/71 [==============================] - 7s 73ms/step\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "          cocoa       0.00      0.00      0.00        12\n",
            "          grain       0.19      0.87      0.32       105\n",
            "        veg-oil       0.00      0.00      0.00        20\n",
            "           earn       0.92      0.79      0.85       813\n",
            "            acq       0.66      0.85      0.74       474\n",
            "          wheat       0.00      0.00      0.00         5\n",
            "         copper       0.00      0.00      0.00        14\n",
            "        housing       0.00      0.00      0.00         3\n",
            "   money-supply       0.00      0.00      0.00        38\n",
            "         coffee       0.00      0.00      0.00        25\n",
            "          sugar       0.00      0.00      0.00        30\n",
            "          trade       0.31      0.45      0.36        83\n",
            "       reserves       0.00      0.00      0.00        13\n",
            "           ship       0.17      0.22      0.19        37\n",
            "         cotton       0.00      0.00      0.00         2\n",
            "        carcass       0.00      0.00      0.00         9\n",
            "          crude       0.21      0.37      0.27        99\n",
            "        nat-gas       0.00      0.00      0.00        12\n",
            "            cpi       0.00      0.00      0.00        20\n",
            "       money-fx       0.49      0.47      0.48       133\n",
            "       interest       0.00      0.00      0.00        70\n",
            "            gnp       0.00      0.00      0.00        27\n",
            "      meal-feed       0.00      0.00      0.00         7\n",
            "           alum       0.00      0.00      0.00        12\n",
            "        oilseed       0.00      0.00      0.00        19\n",
            "           gold       0.00      0.00      0.00        31\n",
            "            tin       0.00      0.00      0.00         8\n",
            "strategic-metal       0.00      0.00      0.00         4\n",
            "      livestock       0.00      0.00      0.00        10\n",
            "         retail       0.00      0.00      0.00         4\n",
            "            ipi       0.00      0.00      0.00        12\n",
            "     iron-steel       0.00      0.00      0.00        13\n",
            "         rubber       0.00      0.00      0.00        10\n",
            "           heat       0.00      0.00      0.00         5\n",
            "           jobs       0.00      0.00      0.00         7\n",
            "            lei       0.00      0.00      0.00         6\n",
            "            bop       0.00      0.00      0.00        11\n",
            "           zinc       0.00      0.00      0.00         2\n",
            "         orange       0.00      0.00      0.00         3\n",
            "       pet-chem       0.00      0.00      0.00         5\n",
            "            dlr       0.00      0.00      0.00        10\n",
            "            gas       0.00      0.00      0.00         8\n",
            "         silver       0.00      0.00      0.00         3\n",
            "            wpi       0.00      0.00      0.00         6\n",
            "            hog       0.00      0.00      0.00         5\n",
            "           lead       0.00      0.00      0.00         1\n",
            "\n",
            "       accuracy                           0.57      2246\n",
            "      macro avg       0.06      0.09      0.07      2246\n",
            "   weighted avg       0.53      0.57      0.54      2246\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/wwami/.pyenv/versions/3.11.2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/wwami/.pyenv/versions/3.11.2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/wwami/.pyenv/versions/3.11.2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Get the predicted labels\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# Convert the predicted probabilities to labels\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Print the classification report\n",
        "print(classification_report(y_test, y_pred, target_names=class_names))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
